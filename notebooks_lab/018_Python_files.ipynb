{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 018 Files and other Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "\n",
    "### Purpose\n",
    "\n",
    "In this session, we will learn about files and similar resources. We will introduce the standard Python library [`pathlib`](https://docs.python.org/3/library/pathlib.html) which is how we deal with file paths, as well as the useful package [`urlpath`](https://github.com/chrono-meter/urlpath) that allows a similar object-oriented approach with files and other objects on the web. We will also cover opening and closing files, and some simple read- and write-operations.\n",
    "\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You will need some understanding of the following:\n",
    "\n",
    "\n",
    "* [001 Using Notebooks](001_Notebook_use.ipynb)\n",
    "* [005 Getting help](005_Help.ipynb)\n",
    "\n",
    "Remember that you can 'run' the code in a code block using the 'run' widget (above) or hitting the keys ('typing') <shift> and <return> at the same time. \n",
    "\n",
    "### Timing\n",
    "\n",
    "The session should take around XX hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource location\n",
    "\n",
    "\n",
    "We store information on a computer in files, or file-like resources. We will use the term 'file' below to mean either of these concepts, other than specific issues relating to particular types of file/resource.\n",
    "\n",
    "To get information from files, we need to be able to specify some **address** for the file/resource location, along with some way of interacting with the file. These concepts are captured in the idea of a [URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier) (Uniform Resource Indicator). You will most likely have come across the related idea of a [Uniform Resource Locator (URL)](https://en.wikipedia.org/wiki/URL), which is a URL such as [https://www.geog.ucl.ac.uk/people/academic-staff/philip-lewis](https://www.geog.ucl.ac.uk/people/academic-staff/philip-lewis)\n",
    "that gives:\n",
    "\n",
    "* the location of the resource: `people/academic-staff/philip-lewis`\n",
    "* the access and interpretation protocol: [`https`](https://en.wikipedia.org/wiki/HTTPS) (secure [`http`](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol))\n",
    "* the network domain name: [`www.geog.ucl.ac.uk`](https://www.geog.ucl.ac.uk)\n",
    "\n",
    "When we visit this URL using an appropriate tool such as a browser, the tool can access and interpret the information in the resource: in this case, interpret the [html code](https://www.w3schools.com/html) in the file pointed to by the URL.\n",
    "\n",
    "Similarly, we will be used to the idea of accessing `files` on the computer. These may be in the local file system, or on some network or cloud storage that might be accessible from the local file system. An example of such a file would be some Python code file such as \n",
    "[`geog0111/helloWorld.py`](http://localhost:8888/edit/notebooks/geog0111/helloWorld.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this idea to make a dictionary of our ENSO dataset, using the items in the header for the keys. In this way, we obtain a  more elegant representation of the dataset, and can refer to items by names (keys) instead of column numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# access dataset as above\n",
    "url = \"http://www.esrl.noaa.gov/psd/enso/mei.old/table.html\"\n",
    "txt = requests.get(url).text\n",
    "\n",
    "# copy the useful data\n",
    "start_head = txt.find('YEAR')\n",
    "start_data = txt.find('1950\\t')\n",
    "stop_data  = txt.find('2018\\t')\n",
    "\n",
    "header = txt[start_head:start_data].split()\n",
    "data = np.loadtxt(io.StringIO(txt[start_data:stop_data]),unpack=True)\n",
    "\n",
    "# use zip to load into a dictionary\n",
    "data_dict = dict(zip(header, data))\n",
    "\n",
    "key = 'MAYJUN'\n",
    "# plot data\n",
    "plt.figure(0,figsize=(12,7))\n",
    "plt.title('ENSO data from {0}'.format(url))\n",
    "plt.plot(data_dict['YEAR'],data_dict[key],label=key)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('ENSO')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3.5**\n",
    "\n",
    "* copy the code above, and modify so that datasets for months `['MAYJUN','JUNJUL','JULAUG']` are plotted on the graph\n",
    "\n",
    "Hint: use a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do exercise here\n",
    "# ANSWER\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# access dataset as above\n",
    "url = \"http://www.esrl.noaa.gov/psd/enso/mei.old/table.html\"\n",
    "txt = requests.get(url).text\n",
    "\n",
    "# copy the useful data\n",
    "start_head = txt.find('YEAR')\n",
    "start_data = txt.find('1950\\t')\n",
    "stop_data  = txt.find('2018\\t')\n",
    "\n",
    "header = txt[start_head:start_data].split()\n",
    "data = np.loadtxt(io.StringIO(txt[start_data:stop_data]),unpack=True)\n",
    "\n",
    "# use zip to load into a dictionary\n",
    "data_dict = dict(zip(header, data))\n",
    "\n",
    "\n",
    "'''\n",
    "Do the loop here\n",
    "'''\n",
    "for i,key in enumerate(['MAYJUN','JUNJUL','JULAUG']):\n",
    "    # plot data\n",
    "    '''\n",
    "    Use enumeration i as figure number\n",
    "    '''\n",
    "    plt.figure(i,figsize=(12,7))\n",
    "    plt.title('ENSO data from {0}'.format(url))\n",
    "    plt.plot(data_dict['YEAR'],data_dict[key],label=key)\n",
    "    plt.xlabel('year')\n",
    "    plt.ylabel('ENSO')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also usefully use a dictionary with a printing format statement. In that case, we refer directly to the key in ther format string. This can make printing statements much easier to read. We don;'t directly pass the dictionary to the `fortmat` staterment, but rather `**dict`, where `**dict` means \"treat the key-value pairs in the dictionary as additional named arguments to this function call\".\n",
    "\n",
    "So, in the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# access dataset as above\n",
    "url = \"http://www.esrl.noaa.gov/psd/enso/mei/table.html\"\n",
    "txt = requests.get(url).text\n",
    "\n",
    "# copy the useful data\n",
    "start_head = txt.find('YEAR')\n",
    "start_data = txt.find('1950\\t')\n",
    "stop_data  = txt.find('2018\\t')\n",
    "\n",
    "header = txt[start_head:start_data].split()\n",
    "data = np.loadtxt(io.StringIO(txt[start_data:stop_data]),unpack=True)\n",
    "\n",
    "# use zip to load into a dictionary\n",
    "data_dict = dict(zip(header, data))\n",
    "print(data_dict.keys())\n",
    "\n",
    "# print the data for MAYJUN\n",
    "print('data for MAYJUN: {MAYJUN}'.format(**data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line `print('data for MAYJUN: {MAYJUN}'.format(**data_dict))` is equivalent to writing:\n",
    "\n",
    "    print('data for {MAYJUN}'.format(YEAR=data_dict[YEAR],DECJAN=data_dict[DECJAN], ...))\n",
    "    \n",
    "In this way, we use the keys in the dictionary as keywords to pass to a method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful example of such a use of a dictionary is in saving a numpy dataset to file.\n",
    "\n",
    "If the data are numpy arrays in a dictionary as above, we can store the dataset using:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# access dataset as above\n",
    "url = \"http://www.esrl.noaa.gov/psd/enso/mei/table.html\"\n",
    "txt = requests.get(url).text\n",
    "\n",
    "# copy the useful data\n",
    "start_head = txt.find('YEAR')\n",
    "start_data = txt.find('1950\\t')\n",
    "stop_data  = txt.find('2018\\t')\n",
    "\n",
    "header = txt[start_head:start_data].split()\n",
    "data = np.loadtxt(io.StringIO(txt[start_data:stop_data]),unpack=True)\n",
    "\n",
    "# use zip to load into a dictionary\n",
    "data_dict = dict(zip(header, data))\n",
    "\n",
    "filename = 'enso_mei.npz'\n",
    "\n",
    "# save the dataset\n",
    "np.savez_compressed(filename,**data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we load from the file is a dictionary-like object `<class 'numpy.lib.npyio.NpzFile'>`.\n",
    "\n",
    "If needed, we can cast this to a dictionary with `dict()`, but it is generally more efficient to keep the original type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "filename = 'enso_mei.npz'\n",
    "\n",
    "loaded_data = np.load(filename)\n",
    "\n",
    "print(type(loaded_data))\n",
    "\n",
    "# test they are the same using np.array_equal\n",
    "for k in loaded_data.keys():\n",
    "    print('\\t',k,np.array_equal(data_dict[k], loaded_data[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3.6**\n",
    "\n",
    "* Using what you have learned above, access the Met Office data file [`https://www.metoffice.gov.uk/hadobs/hadukp/data/monthly/HadSEEP_monthly_qc.txt`](https://www.metoffice.gov.uk/hadobs/hadukp/data/monthly/HadSEEP_monthly_qc.txt) and create a 'data package' in a numpy`.npz` file that has keys of `YEAR` and each month in the year, with associated datasets of Monthly Southeast England precipitation (mm).\n",
    "* confirm that tha data in your `npz` file is the same as in your original dictionary\n",
    "* produce a plot of October rainfall using these data for the years 1900 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do exercise here\n",
    "# ANSWER\n",
    "\n",
    "'''\n",
    "Exploration of dataset shows:\n",
    "\n",
    "\n",
    "Monthly Southeast England precipitation (mm). Daily automated values used after 1996.\n",
    "Wigley & Jones (J.Climatol.,1987), Gregory et al. (Int.J.Clim.,1991)\n",
    "Jones & Conway (Int.J.Climatol.,1997), Alexander & Jones (ASL,2001). Values may change after QC.\n",
    "YEAR   JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG   SEP   OCT   NOV   DEC   ANN\n",
    " 1873  87.1  50.4  52.9  19.9  41.1  63.6  53.2  56.4  62.0  86.0  59.4  15.7  647.7\n",
    " 1874  46.8  44.9  15.8  48.4  24.1  49.9  28.3  43.6  79.4  96.1  63.9  52.3  593.5\n",
    "\n",
    "so we have 3 lines of header\n",
    "then the column titles\n",
    "then the data\n",
    "\n",
    "we can define these as before using\n",
    "\n",
    "txt.find('YEAR')\n",
    "start_data = txt.find('1873')\n",
    "stop_data = None\n",
    "\n",
    "\n",
    "Other than the filenames then, the code\n",
    "is identical\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# access dataset as above\n",
    "url = \"https://www.metoffice.gov.uk/hadobs/hadukp/data/monthly/HadSEEP_monthly_qc.txt\"\n",
    "txt = requests.get(url).text\n",
    "\n",
    "# copy the useful data\n",
    "start_head = txt.find('YEAR')\n",
    "start_data = txt.find('1873')\n",
    "stop_data  = None\n",
    "\n",
    "header = txt[start_head:start_data].split()\n",
    "data = np.loadtxt(io.StringIO(txt[start_data:stop_data]),unpack=True)\n",
    "\n",
    "# use zip to load into a dictionary\n",
    "data_dict = dict(zip(header, data))\n",
    "\n",
    "filename = 'HadSEEP_monthly_qc.npz'\n",
    "\n",
    "# save the dataset\n",
    "np.savez_compressed(filename,**data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "loaded_data = np.load(filename)\n",
    "\n",
    "print(type(loaded_data))\n",
    "\n",
    "# test they are the same using np.array_equal\n",
    "for k in loaded_data.keys():\n",
    "    print('\\t',k,np.array_equal(data_dict[k], loaded_data[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "'''\n",
    "October rainfall, 1900+\n",
    "'''\n",
    "\n",
    "year = loaded_data['YEAR']\n",
    "\n",
    "# mask where years match\n",
    "mask = year  >= 1900\n",
    "\n",
    "oct = loaded_data['OCT']\n",
    "\n",
    "# set invalid data points to nan\n",
    "oct[oct<0] = np.nan\n",
    "\n",
    "plt.plot(year[mask],oct[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Summary\n",
    "\n",
    "In this section, we have extended the types of data we might come across to include groups . We dealt with ordered groups of various types (`tuple`, `list`), and introduced the numpy package for numpy arrays (`np.array`). We saw dictionaries as collections with which we refer to individual items with a key.\n",
    "\n",
    "We learned in the previous section how to pull apart a dataset presented as a string using loops and various using methods and to construct a useful dataset 'by hand' in a list or similar structure. It is useful, when learning to program, to know how to do this.\n",
    "\n",
    "Here, we saw that packages such as numpy provide higher level routines that make reading data easier, and we would generally use these in practice. We saw how we can use `zip()` to help load a dataset from arrays into a dictionary, and also the value of using a dictionary representation when saving numpy files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
