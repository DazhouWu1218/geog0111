{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='UCL' src=\"images/ucl_logo.png\" align='center'>\n",
    "\n",
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](016_Python_for.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](018_Python_xxx.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 021 Read Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "### Purpose\n",
    "\n",
    "In this session, we will learn how to read files and similar resources. We will mainly use [`pathlib`](https://docs.python.org/3/library/pathlib.html) and the local package [gurlpath](geog0111/gurlpath) derived from [`urlpath`](https://github.com/chrono-meter/urlpath). We will also cover opening and closing files, and some simple read- and write-operations.\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You will need some understanding of the following:\n",
    "\n",
    "\n",
    "* [001 Using Notebooks](001_Notebook_use.ipynb)\n",
    "* [002 Unix](002_Unix.ipynb) with a good familiarity with the UNIX commands we have been through.\n",
    "* [003 Getting help](003_Help.ipynb)\n",
    "* [010 Variables, comments and print()](010_Python_Introduction.ipynb)\n",
    "* [011 Data types](011_Python_data_types.ipynb) \n",
    "* [012 String formatting](012_Python_strings.ipynb)\n",
    "* [013_Python_string_methods](013_Python_string_methods.ipynb)\n",
    "* [020_Python_files](020_Python_files.ipynb)\n",
    "\n",
    "You will need to recall details from [020_Python_files](020_Python_files.ipynb) on using the two packages.\n",
    "\n",
    "\n",
    "### Test\n",
    "You will need a web login to NASA Earthdata and to have stored this using `cylog` according to [004_Accounts](004_Accounts.ipynb) for the site `https://e4ftl01.cr.usgs.gov`. We can test this with the following code ius yoiu set do_test to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "# ping small (1.3 M) test file\n",
    "site='https://e4ftl01.cr.usgs.gov/'\n",
    "test_dir='MOLA/MYD11_L2.006/2002.07.04'\n",
    "test_file='MYD11_L2*0325*.hdf'\n",
    "# this glob interprets the wildcards to get at a suitable test file\n",
    "url = URL(site,test_dir).glob(test_file,verbose=False)[0]\n",
    "# test ping returns True\n",
    "assert url.ping(verbose=False) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this fails, set `verbose` to `True` to see what is going on, then if you can;'t work it out from there, go back to [004_Accounts](004_Accounts.ipynb) and sort the login for NASA Earthdata the site `https://e4ftl01.cr.usgs.gov`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "# print out the absolute pathname of the \n",
    "# directory that images/ucl.png is in\n",
    "ucl = Path('images','ucl.png')\n",
    "\n",
    "# use absolute and parent\n",
    "# Use name to show how that is helpful\n",
    "print(f'The directory {ucl.name} is in is: {ucl.absolute().parent}')\n",
    "\n",
    "# check that the file exists\n",
    "# if it does ...\n",
    "if ucl.exists():\n",
    "    # print the size of the file in KB to two decimal places\n",
    "\n",
    "    # from above, use stat().st_size\n",
    "    size_in_bytes = ucl.stat().st_size\n",
    "    # 1024 Bytes -> 1 KB\n",
    "    size_in_KB = size_in_bytes/1024\n",
    "    # 2 dp -> : .2f\n",
    "    print(f'file size {size_in_bytes} Bytes -> {size_in_KB : .2f} KB')\n",
    "else:\n",
    "    print(f'file does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing\n",
    "\n",
    "We can conveniently use `pathlib` to deal with file input and output. The main methods to be aware of are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|command|  purpose|\n",
    "|---|---|\n",
    "|`Path.open()`| open a file and return a file descriptor|\n",
    "|`Path.read_text()`|  read text|\n",
    "|`Path.write_text()`| write text|\n",
    "|`Path.read_bytes()`| read byte data|\n",
    "|`Path.write_bytes()`| write byte data|\n",
    "\n",
    "\n",
    "For `gurlpath` we have the following equivalent functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|command|  purpose|\n",
    "|---|---|\n",
    "|`URL.open()`| open a file descriptor with data from a URL|\n",
    "|`URL.read_text()`|  read text from URL|\n",
    "|`URL.write_text()`| write text to file|\n",
    "|`URL.read_bytes()`| read byte data from URL|\n",
    "|`URL.write_bytes()`| write byte data to file|\n",
    "\n",
    "Notice that the `write` functions (and `open` when used for write) write to local files, not to the URL. \n",
    "\n",
    "They have a keyword argument `local_file` to set the location to write the file to. If this is not given, the the directory structure of the URL is used (relative to the current directory). Alternatively, you can settrhe keyword `local_dr`, or set `URL.local_file` or `URL.local_dir` as appropriate. \n",
    "\n",
    "Note that `URL` is tolerant of calling with a `Path`: if we call `URL` with a local file, most operations will continue and apply the appropriate `Path` function.\n",
    "\n",
    "### `with ... as ...`, `Path.open`, `URL.open`, `yaml`, `json`\n",
    "\n",
    "Quite often, we will use specific packages for reading particular file formats. But often we just need to be able to open a file (to get a file descriptor) or just to read some binary of text data from a file, or write straight binary of text data to a file. We use this suite of functions given above for such taskas. \n",
    "\n",
    "The first of these, `Path.open` provides a file descriptor for the open file. This is used to interface to other input/output functions in Python. A typical example of this is reading a configuration file in [`yaml` format](http://zetcode.com/python/yaml/).\n",
    "\n",
    "The usual way of opening a file to get the file descriptor is:\n",
    "\n",
    "    with Path(filename).open('r') as f:\n",
    "       # do some reading with f\n",
    "       pass\n",
    "       \n",
    "\n",
    "We use the form `with ... as ...` here, so that the file descriptor `f` only exists within this construct and the file is automatically closed when we finish. Codes are spaced in inside the construct, as we have seen in `if ...` or `for ... in ...` constructs.\n",
    "\n",
    "Here, we have set the flag `r` within the `open()` statement (this is the default mode). This means that the file will be opened for *reading* only. Alternatives include `w` for writing, or `w+` for appending.\n",
    "\n",
    "In the following example, we use `Path` to open the file [`bin/copy/environment.yml`](bin/copy/environment.yml) and read it using the `yaml` library. This file specifies which packages are loaded in our Python environment. It has a simple ascii format, but since it is a `yaml` file, we should read it with code that interprets the format correctly and safely into a dictionary. This is done using `yaml.safe_load(f)` with `f` an open file descriptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env is type <class 'dict'>\n",
      "env keys: dict_keys(['name', 'channels', 'dependencies'])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# form the file name\n",
    "yaml_file = Path('bin','copy','environment.yml')\n",
    "\n",
    "with yaml_file.open('r') as f:\n",
    "    env = yaml.safe_load(f)\n",
    "\n",
    "print(f'env is type {type(env)}')\n",
    "print(f'env keys: {env.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent, reading the data from a URL is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env is type <class 'dict'>\n",
      "env keys: dict_keys(['name', 'channels', 'dependencies'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> reading data from https://raw.githubusercontent.com/UCL-EO/geog0111/master/copy/environment.yml\n",
      "--> open() text stream\n"
     ]
    }
   ],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "import yaml\n",
    "\n",
    "# form the file name\n",
    "site = 'https://raw.githubusercontent.com'\n",
    "site_dir = '/UCL-EO/geog0111/master'\n",
    "site_file = 'copy/environment.yml'\n",
    "yaml_file = URL(site,site_dir,site_file)\n",
    "\n",
    "# notice that we can use verbose=True for URL open\n",
    "with yaml_file.open('r',verbose=True) as f:\n",
    "    env = yaml.safe_load(f)\n",
    "\n",
    "print(f'env is type {type(env)}')\n",
    "print(f'env keys: {env.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common file format for configuration information is [`json`](https://www.json.org/json-en.html). We can use the same form of code as above to write the information in `env` into a `json` format file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# form the file name\n",
    "json_file = Path('bin','copy','environment.json')\n",
    "\n",
    "with json_file.open('w') as f:\n",
    "    json.dump(env, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and write text\n",
    "\n",
    "We can read text from a file with `Path.read_text()` or from a URL with `URL.read_text()`, then either `Path.write_text()` or  `URL.write_text()` to write text to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 90 bytes to work/easy.txt\n"
     ]
    }
   ],
   "source": [
    "# from https://www.json.org\n",
    "some_text = '''\n",
    "It is easy for humans to read and write.\n",
    "It is easy for machines to parse and generate. \n",
    "'''\n",
    "\n",
    "# set up the filename\n",
    "outfile = Path('work/easy.txt')\n",
    "# write the text\n",
    "nbytes = outfile.write_text(some_text)\n",
    "# print what we did\n",
    "print(f'wrote {nbytes} bytes to {outfile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 1\n",
    "\n",
    "* Using `Path.read_text()` read the text from the file `work/easy.txt` and print the text returned.\n",
    "* split the text into lines of text using `str.split()` at each newline, and print out the resulting list\n",
    "\n",
    "You learned how to split strings in [013_Python_string_methods](013_Python_string_methods.ipynb#split()-and-join())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have read:\n",
      "\n",
      "It is easy for humans to read and write.\n",
      "It is easy for machines to parse and generate. \n",
      "\n",
      "lines list:\n",
      "['', 'It is easy for humans to read and write.', 'It is easy for machines to parse and generate. ', '']\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Using `Path.read_text()` read the text from the \n",
    "# file `work/easy.txt` and print the text returned.\n",
    "\n",
    "text = Path('work/easy.txt').read_text()\n",
    "print(f'I have read:\\n{text}')\n",
    "\n",
    "# split the text into lines of text using `str.split()` \n",
    "# at each newline, and print out the resulting list\n",
    "text_list = text.split('\\n')\n",
    "print(f'lines list:\\n{text_list}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show that we get the same result reading the same file locally or from the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed URL\n",
      "passed Path\n"
     ]
    }
   ],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "from pathlib import Path\n",
    "\n",
    "# first read the data\n",
    "u = 'https://www.json.org/json-en.html'\n",
    "url = URL(u)\n",
    "# set the output dir\n",
    "url.local_dir='data'\n",
    "\n",
    "data = url.read_text(verbose=False)\n",
    "\n",
    "# write to 'data/json-en.html' with URL\n",
    "osize = url.write_text(data)\n",
    "# test the correct number of bytes\n",
    "assert osize == 26718\n",
    "print('passed URL')\n",
    "\n",
    "# write to 'data/json-en.html' with Path\n",
    "osize = Path('data/json-en.html').write_text(data)\n",
    "# test the correct number of bytes\n",
    "assert osize == 26718\n",
    "print('passed Path')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `URL` class has a few advantages over using `Path` in this way:\n",
    "\n",
    "* if the output directory doesn't already exist, it will be created\n",
    "* if we set a `noclobber=True` flag, then we will not try to write the file if it already exists.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> local file data/json-en.html\n",
      "--> existing file data/json-en.html\n",
      "--> noclobber: True\n",
      "--> opening local file data/json-en.html\n",
      "--> mkdir local dir data\n",
      "--> file exists so not writing\n",
      "--> done : 26880\n"
     ]
    }
   ],
   "source": [
    "from geog0111.gurlpath import URL\n",
    "from pathlib import Path\n",
    "\n",
    "# first read the data\n",
    "u = 'https://www.json.org/json-en.html'\n",
    "url = URL(u)\n",
    "url.local_dir='data'\n",
    "\n",
    "data = url.read_text()\n",
    "\n",
    "# write to 'data/json-en.html' with URL\n",
    "osize = url.write_text(data,verbose=True,noclobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "XXX TODO XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Using Path.read_text() read the text from the file work/easy.txt \n",
    "# and print the text returned.\n",
    "\n",
    "# set up the filename\n",
    "infile = Path('work','easy.txt')\n",
    "# read the text\n",
    "read_text = infile.read_text()\n",
    "\n",
    "# split the text into lines of \n",
    "# text using str.split() at each newline, \n",
    "# and print out the resulting list\n",
    "lines = read_text.split('\\n')\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read and write binary data\n",
    "\n",
    "We can read binary data from a file with `Path.read_bytes()` or from a URL with `URL.read_bytes()`, then either `Path.write_bytes()` or  `URL.write_bytes()` to write the binary data to a file.\n",
    "\n",
    "Let's first access a MODIS file from the web, as we did in [020_Python_files](020_Python_files.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> wildcards in: ['*.h08v06*.hdf']\n",
      "--> level 0/1 : *.h08v06*.hdf\n",
      "--> trying https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01\n",
      "--> discovered 1 files with pattern *.h08v06*.hdf in https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2020.01.01\n"
     ]
    }
   ],
   "source": [
    "from  geog0111.modis import Modis\n",
    "\n",
    "modis = Modis('MCD15A3H',verbose=True)\n",
    "url = modis.get_url(\"2020\",\"01\",\"01\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pull the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> local file work/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf\n",
      "--> opening local file work/MCD15A3H.A2020001.h08v06.006.2020006032951.hdf\n",
      "--> mkdir local dir work\n",
      "--> writing data ...\n",
      "--> done : 9067184\n",
      "--> done : 9067184\n"
     ]
    }
   ],
   "source": [
    "# set the output directory\n",
    "url.local_dir = 'work'\n",
    "# read the dataset\n",
    "hdf_data = url.read_bytes()\n",
    "# and save to a file\n",
    "obytes = url.write_bytes(hdf_data,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Using the code:\n",
    "    \n",
    "    from  geog0111.modis import Modis\n",
    "\n",
    "    # get URL\n",
    "    modis = Modis('MCD15A3H',verbose=True)\n",
    "    url = modis.get_url(\"2020\",\"01\",\"01\")[0]\n",
    "    # set the output directory\n",
    "    url.local_dir = 'work'\n",
    "    \n",
    "    # read the dataset\n",
    "    hdf_data = url.read_bytes()\n",
    "    # and save to a file\n",
    "    obytes = url.write_bytes(hdf_data,verbose=True)    \n",
    "\n",
    "* write a function that only calls `url.read_bytes()` if the file doesn't already exist\n",
    "* If it already exists, just read the data from that file\n",
    "* test your code with the url generated above and show that the file size is 9067184 bytes\n",
    "\n",
    "You will need to remember how to get the filename from the URL object, and also to test if a file exists. We learned all of these in [020_Python_files](020_Python_files.ipynb).\n",
    "\n",
    "Note that `len(data)` will give the size of bytes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "# write a function that only calls url.read_bytes() \n",
    "# if the file doesn't already exist\n",
    "def get_data(url,verbose=False,local_dir='work'):\n",
    "    '''\n",
    "    Get the binary data from url if the \n",
    "    output file doesnt exist\n",
    "    \n",
    "    Positional Arguments:\n",
    "    url  : a URL object\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    verbose  : Bool -> False\n",
    "    local_dir : str -> work\n",
    "    '''\n",
    "    # get the output file name\n",
    "    # url.name gives the file name from the URL\n",
    "    ofile = Path(local_dir,url.name)\n",
    "    \n",
    "    # test exists\n",
    "    if ofile.exists():\n",
    "        # If it already exists, \n",
    "        # just read the data from that file\n",
    "        return ofile.read_bytes()\n",
    "    \n",
    "    # otherwise read data from url:\n",
    "    # set output dir\n",
    "    url.local_dir = local_dir\n",
    "    # pass on verbose flag\n",
    "    hdf_data = url.read_bytes(verbose=verbose)\n",
    "    # \n",
    "    obytes = url.write_bytes(hdf_data,verbose=True)\n",
    "    return hdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "from  geog0111.modis import Modis\n",
    "modis = Modis('MCD15A3H',verbose=False)\n",
    "url = modis.get_url(\"2020\",\"01\",\"01\")[0]\n",
    "\n",
    "hdf_data = get_data(url,verbose=True,local_dir='work')\n",
    "assert len(hdf_data) ==  9067184\n",
    "print('passed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "#### Exercise 4\n",
    "\n",
    "* print out the absolute pathname of the directory that the binary file [`images/ucl.png`](images/ucl.png) is in\n",
    "* print the size of the file in kilobytes (KB) to two decimal places without reading the datafile. \n",
    "* read the datafile, and check you get the same data size\n",
    "\n",
    "You will need to recall how to find a file size in bytes using `Path`. This was covered in [020_Python_files](020_Python_files.ipynb). You will need to know how many bytes are in a KB. To print to two decimal places, you need to recall the string formatting we did in [012_Python_strings](012_Python_strings.ipynb#String-formating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/plewis/Documents/GitHub/geog0111/notebooks/images/ucl.png\n",
      "the file ucl.png is in /Users/plewis/Documents/GitHub/geog0111/notebooks/images\n",
      "ucl.png has size 1956 bytes\n",
      "ucl.png has size 1.91 KB\n",
      "the size of data read is 1956 bytes ->  1.91 KB\n"
     ]
    }
   ],
   "source": [
    "# ANSWER \n",
    "\n",
    "# print out the absolute pathname of the \n",
    "# directory that images/ucl.png is in\n",
    "abs_name = Path('images/ucl.png').absolute()\n",
    "print(abs_name)\n",
    "\n",
    "# we want the parent!\n",
    "print(f'the file {abs_name.name} is in {abs_name.parent}')\n",
    "\n",
    "# print the size of the file in bytes without reading the datafile. \n",
    "print(f'{abs_name.name} has size {abs_name.stat().st_size} bytes')\n",
    "\n",
    "# 1 KB is 1024 Bytes\n",
    "# .2f is 2 d.p. format\n",
    "print(f'{abs_name.name} has size ' +\\\n",
    "      f'{abs_name.stat().st_size/1024:.2f} KB')\n",
    "\n",
    "# read the datafile, and check you get the same data size\n",
    "dataset = abs_name.read_bytes()\n",
    "# size\n",
    "s = len(dataset)\n",
    "print(f'the size of data read is {s} bytes -> {s/1024 : .2f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Summary\n",
    "\n",
    "In this section, we have used `Path` and `URL` classes to read and write text and binary files. We have combined these ideas with earlier work to download and save a MODIS datafile and other text and binary datasets. We have refreshed our memory of some of the earlier material, especially string formatting.\n",
    "\n",
    "You should now have some confidence in these matters, so that if you were set a task of downloading and saving datasets, as well as other tasks such as finding their size, whether the exists or not, you could do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](016_Python_for.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](014_Python_groups.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
